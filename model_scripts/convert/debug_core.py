# File: debug_core.py

from transformers import AutoTokenizer

MODEL_NAME = "bert-base-uncased"

print(f"--- Testing Core Tokenizer: {MODEL_NAME} ---")

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    print("Tokenizer loaded successfully.")

    # Call the tokenizer with padding=True
    inputs = tokenizer("Hello, world!", padding=True, return_tensors="pt")
    print("Tokenizer called with padding=True.")

    print("\n--- RESULTS ---")
    print("Keys generated by the tokenizer:")
    print(inputs.keys())
    print("-----------------")

    if 'attention_mask' in inputs:
        print("\n✅ SUCCESS: Core tokenizer is working correctly.")
    else:
        print("\n❌ FAILURE: Core tokenizer is NOT working correctly.")

except Exception as e:
    print(f"\nAn unexpected error occurred: {e}")